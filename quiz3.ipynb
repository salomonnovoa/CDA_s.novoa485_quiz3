{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot       as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos el código\n",
    "df = pd.read_csv('insurance.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las dummies\n",
    "data = pd.get_dummies(df,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>10600.54830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>2205.98080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1629.83350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>2007.94500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>29141.36030</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children      charges  sex_male  smoker_yes  \\\n",
       "0      19  27.900         0  16884.92400         0           1   \n",
       "1      18  33.770         1   1725.55230         1           0   \n",
       "2      28  33.000         3   4449.46200         1           0   \n",
       "3      33  22.705         0  21984.47061         1           0   \n",
       "4      32  28.880         0   3866.85520         1           0   \n",
       "...   ...     ...       ...          ...       ...         ...   \n",
       "1333   50  30.970         3  10600.54830         1           0   \n",
       "1334   18  31.920         0   2205.98080         0           0   \n",
       "1335   18  36.850         0   1629.83350         0           0   \n",
       "1336   21  25.800         0   2007.94500         0           0   \n",
       "1337   61  29.070         0  29141.36030         0           1   \n",
       "\n",
       "      region_northwest  region_southeast  region_southwest  \n",
       "0                    0                 0                 1  \n",
       "1                    0                 1                 0  \n",
       "2                    0                 1                 0  \n",
       "3                    1                 0                 0  \n",
       "4                    1                 0                 0  \n",
       "...                ...               ...               ...  \n",
       "1333                 1                 0                 0  \n",
       "1334                 0                 0                 0  \n",
       "1335                 0                 1                 0  \n",
       "1336                 0                 0                 1  \n",
       "1337                 1                 0                 0  \n",
       "\n",
       "[1338 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bmi', 'children', 'charges', 'sex_male', 'smoker_yes',\n",
       "       'region_northwest', 'region_southeast', 'region_southwest'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacamos los features\n",
    "features = ['age', 'bmi', 'children', 'sex_male', 'smoker_yes',\n",
    "       'region_northwest', 'region_southeast', 'region_southwest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos la info\n",
    "X = data[features]\n",
    "Y = data.charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divimos en test y train \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos min max\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.280872</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.276029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.328222</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.638687</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.348130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.360371</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.511165</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.168415</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.322303</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>936 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1    2    3    4    5    6    7\n",
       "0    0.695652  0.281141  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "1    0.065217  0.280872  0.2  0.0  0.0  0.0  0.0  1.0\n",
       "2    0.152174  0.276029  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "3    0.695652  0.328222  0.6  0.0  0.0  0.0  1.0  0.0\n",
       "4    0.717391  0.638687  0.2  1.0  0.0  0.0  0.0  1.0\n",
       "..        ...       ...  ...  ...  ...  ...  ...  ...\n",
       "931  0.913043  0.348130  0.0  1.0  0.0  0.0  0.0  1.0\n",
       "932  0.173913  0.360371  0.4  0.0  0.0  0.0  0.0  0.0\n",
       "933  0.717391  0.511165  0.4  0.0  1.0  0.0  0.0  0.0\n",
       "934  0.478261  0.168415  0.4  0.0  1.0  0.0  1.0  0.0\n",
       "935  0.847826  0.322303  0.2  1.0  0.0  0.0  1.0  0.0\n",
       "\n",
       "[936 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13270.422265141257, 6063.40624951856, 0.45691132718857896)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacemos la primera regresión lineal, \n",
    "\n",
    "lr = linear_model.SGDRegressor( penalty='none',n_iter_no_change= 1000)\n",
    "lr.fit(X_train_scaled, Y_train)\n",
    "preds_test = lr.predict(X_test_scaled)\n",
    "data.charges.mean(),mean_squared_error(Y_test, preds_test, squared=False), mean_squared_error(Y_test, preds_test, squared=False)/data.charges.mean()\n",
    "\n",
    "# Teniendo en cuenta que el modelo SGDRegressor utiliza el gradiente decendiente por default, este sería la regresión lineal que busca minimizar el error de predicción. Obtenemos\n",
    "# un error porcentual de 45%, calculado a partir del RMSE y la media de charges, lo cual es un error bastante alto, casi de la mitad del promedio de los charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.419155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.718809</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.566048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.514650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.556094</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.170568</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.672182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.718809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.466505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.345036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.298628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.299704</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2    3    4    5    6    7    8         9    ...  \\\n",
       "0    1.0  0.021739  0.526500  0.0  1.0  0.0  1.0  0.0  0.0  0.000473  ...   \n",
       "1    1.0  0.847826  0.419155  0.0  1.0  0.0  1.0  0.0  0.0  0.718809  ...   \n",
       "2    1.0  0.717391  0.566048  0.0  1.0  0.0  0.0  0.0  1.0  0.514650  ...   \n",
       "3    1.0  0.673913  0.556094  0.6  0.0  0.0  0.0  1.0  0.0  0.454159  ...   \n",
       "4    1.0  0.065217  0.170568  0.2  1.0  0.0  0.0  0.0  1.0  0.004253  ...   \n",
       "..   ...       ...       ...  ...  ...  ...  ...  ...  ...       ...  ...   \n",
       "397  1.0  0.847826  0.672182  0.0  1.0  0.0  0.0  0.0  0.0  0.718809  ...   \n",
       "398  1.0  0.043478  0.466505  0.0  0.0  0.0  0.0  0.0  1.0  0.001890  ...   \n",
       "399  1.0  0.043478  0.345036  0.0  0.0  0.0  0.0  0.0  0.0  0.001890  ...   \n",
       "400  1.0  0.173913  0.298628  0.0  1.0  1.0  0.0  1.0  0.0  0.030246  ...   \n",
       "401  1.0  0.673913  0.299704  0.2  0.0  0.0  0.0  0.0  1.0  0.454159  ...   \n",
       "\n",
       "     155  156  157  158  159  160  161  162  163  164  \n",
       "0    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "397  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "398  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "399  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "400  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "401  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "\n",
       "[402 rows x 165 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se polinomizan las variables\n",
    "\n",
    "poly = PolynomialFeatures(3)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.fit_transform(X_test_scaled)\n",
    "pd.DataFrame(X_test_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hacen pruebas para armar el ciclo de hiperparámetros y resutlados\n",
    "lr = linear_model.SGDRegressor(alpha=0.0001,  eta0=0.01, penalty='none',n_iter_no_change= 1000)\n",
    "#lr = linear_model.SGDRegressor(alpha=0.0001,  eta0=0.01, penalty='elasticnet',n_iter_no_change= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(n_iter_no_change=1000, penalty='none')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_poly, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = lr.predict(X_train_poly)\n",
    "preds_test = lr.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13270.422265141257, 4629.504705068348, 0.34885888425940526)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.charges.mean(),mean_squared_error(Y_train, preds_train, squared=False), mean_squared_error(Y_train, preds_train, squared=False)/data.charges.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13270.422265141257, 4827.675756756294, 0.3637921733234994)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.charges.mean(),mean_squared_error(Y_test, preds_test, squared=False), mean_squared_error(Y_test, preds_test, squared=False)/data.charges.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al comparar los resultados de los errores del train y del test, se evidencia que no hay overfitting, 1. Porque en la información de train, los coeficientes no tienen\n",
    "# un comportamiento que permita predecir muy bien los charges, tiene un error % de 35% y para la parte test, el error ed de 36%, lo cual es muy parecido al de train, por lo cual\n",
    "# no cumple con las caracteristicas para ser determinado como overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crean los hiperparámentros\n",
    "\n",
    "polinomio = [1,2,3,4]\n",
    "penalidad = ['l2', 'l1', 'elasticnet','none']\n",
    "alpha = [0.1,0.01,0.001,0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/salomonnovoamontenegro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Se crean los ciclos con los hiperparámetros y resultados\n",
    "\n",
    "results = pd.DataFrame()\n",
    "df_2 = pd.DataFrame()\n",
    "for i in polinomio:\n",
    "    poly = PolynomialFeatures(i)\n",
    "    X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "    X_test_poly = poly.fit_transform(X_test_scaled)\n",
    "    for j in penalidad:\n",
    "        for k in alpha:\n",
    "            lr = linear_model.SGDRegressor(alpha=k, penalty=j,n_iter_no_change= 1000000)\n",
    "            lr.fit(X_train_poly, Y_train)\n",
    "            preds_test = lr.predict(X_test_poly)\n",
    "            error_percet=mean_squared_error(Y_test, preds_test, squared=False)/data.charges.mean()\n",
    "            \n",
    "            df_2 = [[i, j,k,error_percet]]\n",
    "            df2 = pd.DataFrame(df_2,columns=['poly', 'pen', 'alpha','error_percet'])\n",
    "\n",
    "            #results = pd.concat(results,df_2)\n",
    "#            results.append(df_2)\n",
    "\n",
    "            results=pd.concat([results, df2], ignore_index=True)\n",
    "#            results = pd.concat(df_2)\n",
    "\n",
    "            \n",
    "            #df_2['poly'] = i\n",
    "            #df_2['pen'] = j\n",
    "            #df_2['alpha'] = k\n",
    "            #df_2['error_percet'] = error_percet\n",
    "\n",
    "#            results = results.append(df_2, ignore_index=True)\n",
    "\n",
    "#            print(str(i)+' '+j+' '+str(k)+' '+str(error_percet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poly</th>\n",
       "      <th>pen</th>\n",
       "      <th>alpha</th>\n",
       "      <th>error_percet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.358713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    poly pen   alpha  error_percet\n",
       "27     3  l2  0.0001      0.358713"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se escogen los hiperparámentros que ofrecen el menor error %, el cual es de 35%, 10% menor que la regresión inicial\n",
    "\n",
    "results[results.error_percet ==results.error_percet.min() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "results.groupby('alpha')['error_percet'].mean().plot.bar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='pen'>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "results.groupby('pen')['error_percet'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='poly'>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "results.groupby('poly')['error_percet'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuestas concisas (Las explicaciones más extensas están en cada parte del análisis):\n",
    "1. No es aceptable el error obtenido incialmente, teniendo en cuenta que es un error % de 45%, muy cercano a la mitad, lo cual lo hace muy alto\n",
    "2. No no hay evidencia de overfitting, por la predicción de los coeficientes de train y la comparación del resutlado de y_train con y_test\n",
    "3. Si, si fue posible con Polinomización grado 3, Pnalización L2, Alpha = 0.0001, se logró un error % de 36%, 9% menos\n",
    "4. El hiperparámetro que parece mostrar la mayor de diferencia en los errores, es el grado de polinomio; este análisis no se hace anivel de coeficiente, teniendo en cuenta que el mejor resultado es con polinomio grado 3, por lo cual no se puede concluir, sobre los coeficientes \"ceteris paribus\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13f9544095a943129cf4198d14f8af854ab9f8e22442fcc05e89a15741ea364a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
